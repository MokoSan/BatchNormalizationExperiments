{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Normalization\n",
    "\n",
    "<img src=\"https://api.ning.com/files/EXPL4V-n0-S-UQNnNq6bext-hycLoK-u6aEjnY7J2UyCWgn3eFDfbFC0T*6wIFSowUo2bxbUThjv1YqkRXddrKjFeLP8ZXqE/N2.jpg\" width=\"400\" height=\"50\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose of Batch Normalization is to reduce overall __Covariant Shift__ that is a result of changing parameters from the previous layers are constantly changing. The effect of utilizing Batch Normalization is the ability to use higher learning rates and be less careful about weight initialization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: Activations Over Time\n",
    "\n",
    "### DataSet \n",
    "\n",
    "MNIST dataset\n",
    "\n",
    "### Neural Network Architecture:\n",
    "1. 3 Fully Connected Hidden Layers\n",
    "2. 100 Activations Per Hidden Layer\n",
    "3. Each Hidden Layer uses Sigmoid \n",
    "4. Weights initialized to small Gaussian Values\n",
    "5. Last Layer is connected to 10 Activation Layer and Cross Entropy\n",
    "\n",
    "### Training\n",
    "Training on 50,000 steps with 60 examples each per minibatch. \n",
    "\n",
    "### Experimental Observation \n",
    "Comparisons Made between Baseline [ Without Batch Norm ] and Batch Norm at Every Layer\n",
    "\n",
    "### Graphs\n",
    "1. Test Accuracy of the MNIST Network trained with and without Batch Normalization vs. the number of training steps.\n",
    "2. The evolution of input distributions to a typical sigmoid over the course of training shown at 15th, 50th and 85th Percentile. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: ImageNet Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
